{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5457acc-093a-4d4c-b828-b3e5d23d99b1",
   "metadata": {},
   "source": [
    "# Tic-tac-toe minmax algorithm with search limits\n",
    "We will demonstrate the minmax algorithm on a game played on a 3x3 game board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f52a5e-f1a6-4381-8f90-ccc2cad21c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f788e6",
   "metadata": {},
   "source": [
    "The State class captures the current state of the game.\n",
    "* **Attributes**\n",
    "    * gameplan - 3x3 game board with values 0 to 2\n",
    "    * player - the player who is currently on the turn\n",
    "    * current_player - the player will analyze the game and keep track of possible new states. Players take turns, so the new state should be viewed from the perspective of the opposing player. the player who is on the turn in the current state when searching the state space\n",
    "    * depth - the depth of the analyzed state\n",
    "    * max_depth - how many moves ahead the maximum is looking. If depth = max_depth, I don't analyze the game any further.\n",
    "\n",
    "* **Methods**\n",
    "    * terminal_test - method returns information whether the current state is final or not. If it is, it returns the winner.\n",
    "    * utility - the method tries to evaluate the current state from the player's perspective. In the basic version, it only distinguishes whether the player wins, doesn't win or the move doesn't lead to the end of the game.\n",
    "    * possible_actions - the method returns a list of possible moves. In the case of biscuits, this will be the coordinates of the playing area where the playing stone can be placed.\n",
    "    * expand - this method takes the current state and action definition (the coordinates where to place the die) and creates a new game state.\n",
    "    * minmax - custom implementation of the minmax algorithm\n",
    "    * next_current_player - returns the opponent to the current_player variable\n",
    "    * next_player - returns the opponents to the player variable    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7b390-57e3-4256-b28d-4d7d3e73a92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\" Capturing the state of the game\n",
    "    gameplan - two-dimensional 3x3 array\n",
    "             - 0 - empty array\n",
    "             - 1 - X\n",
    "             - 2 - O\n",
    "    \"\"\"\n",
    "\n",
    "    generated = 0\n",
    "\n",
    "    def __init__(self, gameplan, player, current_player=None, depth=0, max_depth=3):\n",
    "        self.gameplan = gameplan\n",
    "        self.player = player\n",
    "        if current_player is None:\n",
    "            self.current_player = player\n",
    "        else:\n",
    "            self.current_player = current_player\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        State.generated += 1\n",
    "\n",
    "    def terminal_test(self):\n",
    "        \n",
    "\n",
    "        # horizontal and vertical triplets\n",
    "        for i in range(3):\n",
    "            if np.array_equal(self.gameplan[i], [1, 1, 1]):\n",
    "                return 1\n",
    "            if np.array_equal(self.gameplan[i], [2, 2, 2]):\n",
    "                return 2\n",
    "            if np.array_equal(self.gameplan[:, i], [1, 1, 1]):\n",
    "                return 1\n",
    "            if np.array_equal(self.gameplan[:, i], [2, 2, 2]):\n",
    "                return 2\n",
    "\n",
    "        # diagonals\n",
    "        if np.array_equal(self.gameplan.diagonal(), [1, 1, 1]):\n",
    "            return 1\n",
    "        if np.array_equal(self.gameplan.diagonal(), [2, 2, 2]):\n",
    "            return 2\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [1, 1, 1]):\n",
    "            return 1\n",
    "        if np.array_equal(np.fliplr(self.gameplan).diagonal(), [2, 2, 2]):\n",
    "            return 2\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def utility(self, result):\n",
    "        if result == 0:\n",
    "            return 0\n",
    "        elif result == self.player:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def possible_actions(self):\n",
    "        possible_actions = []\n",
    "        # Finding empty playing fields\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.gameplan[i][j] == 0:\n",
    "                    possible_actions.append((i, j))\n",
    "        return possible_actions\n",
    "\n",
    "    def expand(self, select_action):\n",
    "        if select_action[0] not in range(3):\n",
    "            return None\n",
    "        if select_action[1] not in range(3):\n",
    "            return None\n",
    "\n",
    "        # playing field must be clear\n",
    "        if self.gameplan[select_action[0], select_action[1]] != 0:\n",
    "            return None\n",
    "        \n",
    "        new_array = np.copy(self.gameplan)\n",
    "        new_array[select_action[0], select_action[1]] = self.current_player\n",
    "        return State(new_array, \n",
    "                     self.player, \n",
    "                     self.next_current_player(), \n",
    "                     self.depth + 1, \n",
    "                     max_depth=self.max_depth)\n",
    "        \n",
    "\n",
    "    def minmax(self, strategy=\"max\"):\n",
    "        \"\"\"\"\n",
    "        The method selects the one that matches the strategy from the possible actions for the given game state\n",
    "\n",
    "        stategy \n",
    "        \"\"\"\n",
    "        \n",
    "        # checking the state of the game.\n",
    "        result = self.terminal_test()\n",
    "        if result != 0:            \n",
    "            return self.utility(result), action\n",
    "        \n",
    "\n",
    "        # initialization of values for each strategy\n",
    "        if strategy == \"max\":\n",
    "            selected_utilization_value = float('-inf')\n",
    "            next_strategy = \"min\"\n",
    "        else:\n",
    "            selected_utilization_value = float('inf')\n",
    "            next_strategy = \"max\"\n",
    "\n",
    "        actions = self.possible_actions()\n",
    "\n",
    "        selected_action = actions[0]\n",
    "\n",
    "        for action in actions:\n",
    "\n",
    "            expanded_state = self.expand(action)\n",
    "\n",
    "            #  check the game ending for expanded state\n",
    "            result = expanded_state.terminal_test()\n",
    "\n",
    "            if result != 0:\n",
    "                return expanded_state.utility(result), action\n",
    "            else:\n",
    "                if len(expanded_state.possible_actions()) == 0:\n",
    "                    utilization = 0\n",
    "                else:\n",
    "                    utilization, _ = expanded_state.minmax(next_strategy)\n",
    "\n",
    "                if utilization > selected_utilization_value and strategy == \"max\":\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "                elif utilization < selected_utilization_value and strategy == \"min\":\n",
    "                    selected_utilization_value = utilization\n",
    "                    selected_action = action\n",
    "\n",
    "        return selected_utilization_value, selected_action\n",
    "\n",
    "    def next_current_player(self):\n",
    "        return 3 - self.current_player\n",
    "\n",
    "    def next_player(self):\n",
    "        return 3 - self.player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340d3be-f984-4633-9453-dca5ee8dc29a",
   "metadata": {},
   "source": [
    "# Task\n",
    "- Add a constraint to the algorithm to limit the maximum search depth.\n",
    "- Try different search depth constraints.\n",
    "- Observe how the times and numbers of generated states change\n",
    "- Are the game results changing?\n",
    "\n",
    "You need to implement a limitation on the # !!! todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d737250e-a504-40ce-a300-27b984c0f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 0)\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Generated states 269175.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 1)\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 26853.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (0, 1)\n",
      "[[1 1 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 2425.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (0, 2)\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "Generated states 77.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (2, 0)\n",
      "[[1 1 2]\n",
      " [0 2 0]\n",
      " [1 0 0]]\n",
      "Generated states 66.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (1, 0)\n",
      "[[1 1 2]\n",
      " [2 2 0]\n",
      " [1 0 0]]\n",
      "Generated states 17.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (1, 2)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 0 0]]\n",
      "Generated states 10.\n",
      "=====================\n",
      "Player 2\n",
      "Select action: (2, 1)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 0]]\n",
      "Generated states 5.\n",
      "=====================\n",
      "Player 1\n",
      "Select action: (2, 2)\n",
      "[[1 1 2]\n",
      " [2 2 1]\n",
      " [1 2 1]]\n",
      "Generated states 2.\n",
      "Drawn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = State(gameplan=np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "              player=1, max_depth=2)\n",
    "while True:\n",
    "    game_result = state.terminal_test()\n",
    "    if game_result != 0:\n",
    "        print(f\"Winner is {game_result} \")\n",
    "        break\n",
    "\n",
    "    if len(state.possible_actions()) == 0:\n",
    "        print(\"Drawn\")\n",
    "        break\n",
    "\n",
    "    print(f\"=====================\\nPlayer {state.player}\")\n",
    "    _, player_action = state.minmax(\"max\")\n",
    "    print(f\"Select action: {player_action}\")\n",
    "    state = state.expand(player_action)\n",
    "    print(state.gameplan)\n",
    "    print(f\"Generated states {State.generated}.\")\n",
    "    State.generated = 0\n",
    "\n",
    "    state.player = state.next_player()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
